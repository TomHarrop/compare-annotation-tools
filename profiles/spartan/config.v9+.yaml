---
executor: cluster-generic
cluster-generic-submit-cmd: mkdir -p logs/slurm/{rule} &&
  sbatch
  --time={resources.runtime}
  {resources.partitionFlag}
  {resources.exclusive}
  --cpus-per-task={threads}
  --mem={resources.mem_mb}
  --job-name=smk-{rule}
  --output=logs/slurm/{rule}/{rule}-%j.out
  --parsable
  --gpus={resources.gpu}
cluster-generic-status-cmd: status-sacct-robust.sh
cluster-generic-cancel-cmd: scancel
default-resources:
  - partitionFlag=""
  - exclusive=""
  - mem_mb=4000
  - runtime=5
  - proj=punim1712
  - gpu=0
set-resources:
  tiberius:
    partitionFlag:"--partition=gpu-a100-short"
    exclusive:"--exclusive",
  helixer:
    partitionFlag:"--partition=gpu-a100-short"
    exclusive:"--exclusive",
restart-times: 0
max-jobs-per-second: 50
max-status-checks-per-second: 10
local-cores: 2
cores: 50
latency-wait: 60
jobs: 128
keep-going: true
keep-storage-local-copies: true
rerun-incomplete: true
printshellcmds: true
use-apptainer: true
use-conda: False
apptainer-args: "-B $PWD,$TMPDIR,/data \
  --nv \
  -H $(mktemp -d) \
  --pwd $PWD \
  --env LC_ALL=C \
  --containall --cleanenv --writable-tmpfs"
rerun-triggers:
  - mtime